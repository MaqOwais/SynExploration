{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6e0057",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import pandas as pd\n",
    "\n",
    "# AdaptiveKDE, Initialiser, Enhancer, AIENs classes (as defined earlier)\n",
    "class AdaptiveKDE:\n",
    "    def __init__(self, data, base_bandwidth=1.0, k=10):\n",
    "        self.data = data\n",
    "        self.k = k\n",
    "        self.base_bandwidth = base_bandwidth\n",
    "        self.kdes = []\n",
    "        self._fit_adaptive_kde()\n",
    "\n",
    "    def _fit_adaptive_kde(self):\n",
    "        distances = pairwise_distances(self.data)\n",
    "        for i in range(self.data.shape[0]):\n",
    "            local_bandwidth = self.base_bandwidth * np.mean(np.sort(distances[i])[:self.k])\n",
    "            kde = KernelDensity(kernel='gaussian', bandwidth=local_bandwidth)\n",
    "            kde.fit(self.data)\n",
    "            self.kdes.append(kde)\n",
    "\n",
    "    def log_prob(self, samples):\n",
    "        log_probs = np.zeros(samples.shape[0])\n",
    "        for kde in self.kdes:\n",
    "            log_probs += kde.score_samples(samples)\n",
    "        return log_probs / len(self.kdes)\n",
    "\n",
    "class Initialiser(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Initialiser, self).__init__()\n",
    "        layers = []\n",
    "        for _ in range(input_dim // 4):\n",
    "            layers.append(nn.Linear(input_dim, input_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.net(z)\n",
    "\n",
    "class Enhancer(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Enhancer, self).__init__()\n",
    "        layers = []\n",
    "        for _ in range(3 * input_dim // 8):\n",
    "            layers.append(nn.Linear(input_dim, input_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.net(z)\n",
    "\n",
    "class AIENs(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(AIENs, self).__init__()\n",
    "        self.initialiser = Initialiser(input_dim)\n",
    "        self.fc_mu = nn.Linear(input_dim, input_dim)\n",
    "        self.fc_logvar = nn.Linear(input_dim, input_dim)\n",
    "        self.enhancer = Enhancer(input_dim)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        latent = self.initialiser(x)\n",
    "        mu, logvar = self.fc_mu(latent), self.fc_logvar(latent)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        reconstruction = self.enhancer(z)\n",
    "        return reconstruction, mu, logvar\n",
    "\n",
    "# Synthetic Data Generation only on enhancer\n",
    "def generate_synthetic_data(model, no_of_sample, input_dim):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Sample latent space\n",
    "        z = torch.randn(no_of_sample, input_dim)\n",
    "        # Generate synthetic data\n",
    "        synthetic_data = model.enhancer(z).numpy()\n",
    "    return synthetic_data\n",
    "\n",
    "def generate_synthetic_data_full_aien(model, no_of_sample, input_dim):\n",
    "    \"\"\"\n",
    "    Generate synthetic data using the full AIENs model.\n",
    "\n",
    "    Parameters:\n",
    "    - model: Trained AIENs model.\n",
    "    - no_of_sample: Number of synthetic samples to generate.\n",
    "    - input_dim: Number of features in the dataset.\n",
    "\n",
    "    Returns:\n",
    "    - synthetic_data: NumPy array of generated synthetic data.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        # Step 1: Sample latent space from standard Gaussian\n",
    "        z = torch.randn(no_of_sample, input_dim)\n",
    "        \n",
    "        # Step 2: Pass through Initialiser to simulate latent space\n",
    "        latent = model.initialiser(z)\n",
    "        \n",
    "        # Step 3: Compute mu and logvar from Initialiser output\n",
    "        mu, logvar = model.fc_mu(latent), model.fc_logvar(latent)\n",
    "        \n",
    "        # Step 4: Reparameterize latent space\n",
    "        z_reparameterized = model.reparameterize(mu, logvar)\n",
    "        \n",
    "        # Step 5: Pass through Enhancer to generate synthetic data\n",
    "        synthetic_data = model.enhancer(z_reparameterized).cpu().numpy()\n",
    "    \n",
    "    return synthetic_data\n",
    "\n",
    "\n",
    "# Load CSV data\n",
    "def load_data(file_path):\n",
    "    data = pd.read_csv(file_path, header=None)\n",
    "    numeric_data = data.iloc[:, :-6].values  # Exclude the class label working with 10 dimensions\n",
    "    return numeric_data\n",
    "\n",
    "# SEKER, BARBUNYA, BOMBAY, CALI, HOROZ\n",
    "def save_synthetic_data(synthetic_data, output_file):\n",
    "    synthetic_df = pd.DataFrame(np.round(synthetic_data, 4), columns=['Area', 'Perimeter', 'MajorAxisLength', 'MinorAxisLength', 'AspectRation', 'Eccentricity', 'ConvexArea', 'EquivDiameter', 'Extent', 'Solidity', 'roundness'])\n",
    "    synthetic_df['Class'] = \"SEKER\"\n",
    "    synthetic_df.to_csv(output_file, index=False)\n",
    "    print(f\"Synthetic data saved to {output_file}\")\n",
    "\n",
    "# Main Script\n",
    "if __name__ == \"__main__\":\n",
    "    # Define dataset and train AIENs as before\n",
    "    input_dim = 10  # Number of columns in dataset\n",
    "    input_file = \"bean1.csv\"\n",
    "    dataset = load_data(input_file)\n",
    "    adaptive_kde = AdaptiveKDE(dataset)\n",
    "    model = AIENs(input_dim)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    # Dummy dataloader\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        torch.from_numpy(dataset).float(), batch_size=32, shuffle=True\n",
    "    )\n",
    "\n",
    "    # Training function\n",
    "    def train_aien(model, dataloader, adaptive_kde, optimizer, num_epochs=50):\n",
    "        model.train()\n",
    "        for epoch in range(num_epochs):\n",
    "            epoch_loss = 0\n",
    "            for batch in dataloader:\n",
    "                x = batch.float()\n",
    "                optimizer.zero_grad()\n",
    "                recon_x, mu, logvar = model(x)\n",
    "                z = model.reparameterize(mu, logvar)\n",
    "                mse_loss = F.mse_loss(recon_x, x, reduction='sum')\n",
    "                kl_div = torch.sum(torch.tensor(adaptive_kde.log_prob(z.cpu().detach().numpy())))\n",
    "                loss = mse_loss - kl_div\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                epoch_loss += loss.item()\n",
    "            print(f\"Epoch {epoch + 1}, Loss: {epoch_loss:.2f}\")\n",
    "\n",
    "    # Train the model\n",
    "    train_aien(model, dataloader, adaptive_kde, optimizer)\n",
    "\n",
    "    # Generate synthetic data\n",
    "    no_of_sample = 500  # Number of synthetic samples to generate\n",
    "    synthetic_data = generate_synthetic_data_full_aien(model, no_of_sample, input_dim)\n",
    "    output_file = \"synthetic_data_1.csv\"\n",
    "    # Save synthetic data to CSV\n",
    "    save_synthetic_data(synthetic_data, output_file)\n",
    "    print(f\"Synthetic data saved to 'synthetic_data.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281efe1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
