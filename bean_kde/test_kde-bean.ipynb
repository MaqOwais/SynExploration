{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f68edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file = 'bean.csv'\n",
    "\n",
    "df = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f513e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477ff091",
   "metadata": {},
   "outputs": [],
   "source": [
    "means_array = df.mean()\n",
    "covariance_matrix = df.cov()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c349c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # prompt\n",
    "# I want to use multivariate kde for synthetic data generation \n",
    "\n",
    "# with mean as each number of dataset and bandwidth as 1 and use the concept of covariance as needed\n",
    "\n",
    "# give me descriptive code in python with nice modularity\n",
    "\n",
    "# the data is collected from .csv file\n",
    "# 0\t5.1\t3.5\t1.4\t0.2\tIris-setosa\n",
    "# 1\t4.9\t3.0\t1.4\t0.2\tIris-setosa\n",
    "# 2\t4.7\t3.2\t1.3\t0.2\tIris-setosa\n",
    "\n",
    "# this is the dataset to consider for e.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b1596af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic data saved to syn_bean_10_5.csv\n",
      "[[3.51332336e+04 7.20112700e+02 2.80902483e+02 ... 7.59205006e-01\n",
      "  9.88348030e-01 8.53879419e-01]\n",
      " [3.73555561e+04 7.42062291e+02 2.97092648e+02 ... 7.13872229e-01\n",
      "  9.89350744e-01 8.56394031e-01]\n",
      " [3.87299573e+04 7.76961614e+02 3.09716916e+02 ... 7.11966455e-01\n",
      "  9.86020651e-01 8.09658674e-01]\n",
      " ...\n",
      " [3.58295972e+04 7.53256789e+02 2.92303713e+02 ... 6.77794542e-01\n",
      "  9.80122669e-01 7.99269826e-01]\n",
      " [3.48757090e+04 7.30924904e+02 2.90603184e+02 ... 6.93628634e-01\n",
      "  9.87328895e-01 8.22708599e-01]\n",
      " [3.86569579e+04 7.61073319e+02 3.02830268e+02 ... 8.03184715e-01\n",
      "  9.84416647e-01 8.38064639e-01]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "# Load CSV data\n",
    "def load_data(file_path):\n",
    "    \"\"\"\n",
    "    Load the Iris dataset from a CSV file and preprocess the numeric values.\n",
    "    \n",
    "    Parameters:\n",
    "        file_path (str): The path to the CSV file.\n",
    "        \n",
    "    Returns:\n",
    "        data (pd.DataFrame): A dataframe containing the numeric data only.\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(file_path, header=None)\n",
    "    numeric_data = data.iloc[:, :-6].values  # Exclude the class label working with 10 classes\n",
    "    return numeric_data\n",
    "\n",
    "# Fit KDE for data generation\n",
    "def fit_kde(data, bandwidth=1.0):\n",
    "    \"\"\"\n",
    "    Fit the Kernel Density Estimation (KDE) model with a Gaussian kernel.\n",
    "    \n",
    "    Parameters:\n",
    "        data (np.array): The original dataset for KDE.\n",
    "        bandwidth (float): The bandwidth parameter for KDE (default: 1.0).\n",
    "        \n",
    "    Returns:\n",
    "        kde_model (KernelDensity): Fitted KDE model.\n",
    "    \"\"\"\n",
    "    kde_model = KernelDensity(bandwidth=bandwidth, kernel='gaussian')\n",
    "    kde_model.fit(data)\n",
    "    return kde_model\n",
    "\n",
    "# Generate synthetic data using KDE\n",
    "def generate_synthetic_data(kde_model, n_samples):\n",
    "    \"\"\"\n",
    "    Generate synthetic data using the fitted KDE model.\n",
    "    \n",
    "    Parameters:\n",
    "        kde_model (KernelDensity): Fitted KDE model.\n",
    "        n_samples (int): Number of synthetic samples to generate.\n",
    "        \n",
    "    Returns:\n",
    "        synthetic_data (np.array): Generated synthetic dataset.\n",
    "    \"\"\"\n",
    "    synthetic_data = kde_model.sample(n_samples)\n",
    "    return synthetic_data\n",
    "\n",
    "# Add covariance to adjust synthetic data (optional)\n",
    "def adjust_with_covariance(original_data, synthetic_data):\n",
    "    \"\"\"\n",
    "    Adjust the generated synthetic data using the covariance matrix of the original data.\n",
    "    \n",
    "    Parameters:\n",
    "        original_data (np.array): The original dataset for reference.\n",
    "        synthetic_data (np.array): The synthetic dataset generated from KDE.\n",
    "        \n",
    "    Returns:\n",
    "        adjusted_synthetic_data (np.array): Adjusted synthetic data based on covariance.\n",
    "    \"\"\"\n",
    "    cov_matrix = np.cov(original_data.T)\n",
    "    mean_vector = np.mean(original_data, axis=0)\n",
    "    \n",
    "    adjusted_synthetic_data = []\n",
    "    for sample in synthetic_data:\n",
    "        adjusted_sample = multivariate_normal(mean=mean_vector, cov=cov_matrix, allow_singular=True).rvs()\n",
    "        adjusted_synthetic_data.append(adjusted_sample)\n",
    "    \n",
    "    return np.array(adjusted_synthetic_data)\n",
    "\n",
    "# # Function to save synthetic data to a new CSV file\n",
    "def save_synthetic_data(original_df, synthetic_data, output_file):\n",
    "    \"\"\"Saves synthetic data to a new CSV file.\"\"\"\n",
    "#     Area,Perimeter,MajorAxisLength,MinorAxisLength,AspectRation,Eccentricity,ConvexArea,EquivDiameter,Extent,Solidity,roundness,Compactness,ShapeFactor1,ShapeFactor2,ShapeFactor3,ShapeFactor4,Class\n",
    "\n",
    "#     synthetic_df = pd.DataFrame(np.round(synthetic_data, 2), columns=['Area', 'Perimeter', 'MajorAxisLength', 'MinorAxisLength', 'AspectRation', 'Eccentricity', 'ConvexArea', 'EquivDiameter', 'Extent', 'Solidity', 'roundness', 'Compactness', 'ShapeFactor1', 'ShapeFactor2', 'ShapeFactor3', 'ShapeFactor4'])\n",
    "    synthetic_df = pd.DataFrame(np.round(synthetic_data, 2), columns=['Area', 'Perimeter', 'MajorAxisLength', 'MinorAxisLength', 'AspectRation', 'Eccentricity', 'ConvexArea', 'EquivDiameter', 'Extent', 'Solidity', 'roundness'])\n",
    "#     synthetic_df = pd.DataFrame(np.round(synthetic_data, 2))\n",
    "    #     synthetic_df['Species'] = np.random.choice(original_df['Species'], size=len(synthetic_df))  # Randomly assign species\n",
    "#     synthetic_df.index.name = 'Index'  # Add index as in the original data\n",
    "    synthetic_df['Class'] = \"HOROZ\"\n",
    "    synthetic_df.to_csv(output_file, index=False)\n",
    "    print(f\"Synthetic data saved to {output_file}\")\n",
    "    \n",
    "# Main function to combine all steps\n",
    "def main(file_path, output_file, n_samples=500, bandwidth=1.0):\n",
    "    \"\"\"\n",
    "    Main function to execute the data generation process.\n",
    "    \n",
    "    Parameters:\n",
    "        file_path (str): Path to the CSV file containing the dataset.\n",
    "        n_samples (int): Number of synthetic samples to generate (default: 100).\n",
    "        bandwidth (float): Bandwidth for KDE (default: 1.0).\n",
    "        \n",
    "    Returns:\n",
    "        final_synthetic_data (np.array): Final synthetic data after adjustments.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load and preprocess data\n",
    "    df = load_data(file_path)\n",
    "    \n",
    "    # Fit KDE model\n",
    "    kde_model = fit_kde(df, bandwidth=bandwidth)\n",
    "    \n",
    "    # Generate synthetic data\n",
    "    synthetic_data = generate_synthetic_data(kde_model, n_samples)\n",
    "    \n",
    "    # Adjust synthetic data using covariance\n",
    "    final_synthetic_data = adjust_with_covariance(df, synthetic_data)\n",
    "#     save_synthetic_data(df, final_synthetic_data, output_file)\n",
    "    save_synthetic_data(df, synthetic_data, output_file)\n",
    "#     final_synthetic_data.to_csv(output_file, index=True)\n",
    "    \n",
    "    return final_synthetic_data\n",
    "#     return synthetic_data\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # File path of the example Iris dataset (modify as needed)\n",
    "    input_file = \"bean5.csv\"\n",
    "    output_file = \"syn_bean_10_5.csv\"  # Output CSV file path\n",
    "\n",
    "    \n",
    "    # Generate 100 synthetic samples\n",
    "    synthetic_data = main(input_file, output_file)\n",
    "    \n",
    "    print(synthetic_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4622fc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
